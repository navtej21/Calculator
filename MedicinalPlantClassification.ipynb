{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navtej21/Calculator/blob/master/MedicinalPlantClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mppIsIBy-hpw",
        "outputId": "52446e96-d942-4edb-c4d2-a5c7dd246ab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.9.0.80)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "!pip install opencv-python-headless\n",
        "!pip install ipywidgets\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install easyprocess\n",
        "!apt-get install -y xvfb\n",
        "\n",
        "# Import libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define a function to process captured frames\n",
        "def process_frame(data_url, model, data):\n",
        "    binary_image = b64decode(data_url.split(',')[1])\n",
        "    nparr = np.frombuffer(binary_image, np.uint8)\n",
        "    frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "\n",
        "    # Preprocess the frame for classification\n",
        "    resized_frame = cv2.resize(frame, (128, 128))\n",
        "    frame_rgb = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB)\n",
        "    frame_normalized = frame_rgb / 255.0\n",
        "    frame_input = frame_normalized[np.newaxis, ...]\n",
        "\n",
        "    # Perform inference with the model\n",
        "    predictions = model.predict(frame_input)\n",
        "    predicted_class = np.argmax(predictions[0])\n",
        "    class_name = data.class_names[predicted_class]\n",
        "\n",
        "    # Display the frame with classification result\n",
        "    cv2.putText(frame, class_name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "    display(frame)\n",
        "\n",
        "# Define a function for capturing frames\n",
        "def capture(data, model, data_dir):\n",
        "    process_frame(data, model, data)\n",
        "\n",
        "# Register the capture function with the notebook\n",
        "from google.colab import output\n",
        "output.register_callback('notebook.capture', capture)\n",
        "\n",
        "# JavaScript code for camera access\n",
        "javascript = \"\"\"\n",
        "async function startCamera() {\n",
        "   const div = document.createElement('div');\n",
        "   document.body.appendChild(div);\n",
        "\n",
        "   const video = document.createElement('video');\n",
        "   video.style.display = 'block';\n",
        "   const stream = await navigator.mediaDevices.getUserMedia({ 'video': true });\n",
        "\n",
        "   div.appendChild(video);\n",
        "   video.srcObject = stream;\n",
        "\n",
        "   await video.play();\n",
        "\n",
        "   // Resize the output to fit the output div\n",
        "   google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "   // Define a function to capture a frame from the webcam\n",
        "   function captureFrame() {\n",
        "       const canvas = document.createElement('canvas');\n",
        "       canvas.width = video.videoWidth;\n",
        "       canvas.height = video.videoHeight;\n",
        "       canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "       return canvas.toDataURL('image/jpeg', 0.8);\n",
        "   }\n",
        "\n",
        "   // Provide a button to capture a frame\n",
        "   const btn = document.createElement('button');\n",
        "   btn.textContent = 'Capture';\n",
        "   div.appendChild(btn);\n",
        "\n",
        "   btn.onclick = () => {\n",
        "       const frame = captureFrame();\n",
        "       google.colab.kernel.invokeFunction('notebook.capture', [frame], {});\n",
        "   };\n",
        "}\n",
        "\n",
        "startCamera();\n",
        "\"\"\"\n",
        "display(Javascript(javascript))\n",
        "\n",
        "# Load the dataset\n",
        "data = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/Training_dataset11',\n",
        "    image_size=(128, 128),\n",
        "    batch_size=16,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Data normalization function\n",
        "def process(image, label):\n",
        "    image = tf.cast(image / 255., tf.float32)\n",
        "    return image, label\n",
        "\n",
        "# Create an ImageDataGenerator for data augmentation\n",
        "data_augmentation = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Define the ResNet model without pre-trained weights\n",
        "resnet_model = keras.applications.ResNet50(\n",
        "    include_top=False,\n",
        "    input_shape=(128, 128, 3),\n",
        "    weights='imagenet'  # Use pre-trained weights\n",
        ")\n",
        "\n",
        "# Adjust the learning rate\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "# Customize the top layers for your number of output classes\n",
        "num_classes = len(data.class_names)\n",
        "top_layers = keras.Sequential([\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256, activation='relu'),      #Additional layers of dense necessary acc to dataset\n",
        "    layers.Dropout(0.5),                       #Should have added more to avoid overfitting\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Combine the base ResNet model and the custom top layers\n",
        "model = keras.Sequential([\n",
        "    resnet_model,\n",
        "    top_layers\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model with more epochs\n",
        "history = model.fit(\n",
        "    data,\n",
        "    epochs=5,  # Increase the number of epochs\n",
        "    validation_data=(data)\n",
        ")\n",
        "\n",
        "# Initialize the webcam capture\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "# Create a loop for webcam integration\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Preprocess the webcam frame\n",
        "    frame = cv2.resize(frame, (128, 128))\n",
        "    frame = frame / 255.0  # Normalize\n",
        "    frame = np.expand_dims(frame, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Classify the frame\n",
        "    predictions = model.predict(frame)\n",
        "    predicted_class = np.argmax(predictions[0])\n",
        "    class_name = data.class_names[predicted_class]\n",
        "\n",
        "    # Display the frame with classification result\n",
        "    cv2.putText(frame, class_name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "    display(frame)"
      ]
    }
  ]
}